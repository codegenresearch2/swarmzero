import os\\\\\nfrom datetime import datetime, timezone\\\\\nfrom typing import Any, List, Optional\\\\\nfrom pathlib import Path\\\\\nfrom llama_index.core.agent.runner.base import AgentRunner\\\\\nfrom llama_index.core.llms import ChatMessage, MessageRole\\\\\nfrom llama_index.core.memory import ChatMemoryBuffer\\\\\nfrom llama_index.core.schema import ImageDocument\\\\\nfrom swarmzero.database.database import DatabaseManager\\\\\nfrom swarmzero.filestore import BASE_DIR, FileStore\\\\\nfile_store = FileStore(BASE_DIR)\\\\\n\\\\nclass ChatManager:\\\\n    def __init__(self, llm: AgentRunner, user_id: str, session_id: str, enable_multi_modal: bool = False):\\\\n        self.llm = llm\\\\n        self.user_id = user_id\\\\n        self.session_id = session_id\\\\n        self.chat_store_key = f"{user_id}_{session_id}"\\\\n        self.enable_multi_modal = enable_multi_modal\\\\n        self.allowed_image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'}\\\\n    def is_valid_image(self, file_path: str) -> bool:\\\\n        return Path(file_path).suffix.lower() in self.allowed_image_extensions\\\\n    async def add_message(self, db_manager: DatabaseManager, role: str, content: Any | None):\\\\n        data = {{\"user_id": self.user_id,\"session_id": self.session_id,\"message": content,\"role": role,\"timestamp": datetime.now(timezone.utc).isoformat()}}\\\\n        if "AGENT_ID" in os.environ:\\\\n            data["agent_id"] = os.getenv("AGENT_ID", "")\\\\n        if "SWARM_ID" in os.environ:\\\\n            data["swarm_id"] = os.getenv("SWARM_ID", "")\\\\n        await db_manager.insert_data("chats", data=data)\\\\n    async def get_messages(self, db_manager: DatabaseManager):\\\\n        filters = {{"user_id": [self.user_id], "session_id": [self.session_id]}}\\\\n        if "AGENT_ID" in os.environ:\\\\n            filters["agent_id"] = os.getenv("AGENT_ID", "")\\\\n        if "SWARM_ID" in os.environ:\\\\n            filters["swarm_id"] = os.getenv("SWARM_ID", "")\\\\n        db_chat_history = await db_manager.read_data("chats", filters)\\\\n        chat_history = [ChatMessage(role=chat["role"], content=chat["message"]) for chat in db_chat_history]\\\\n        return chat_history\\\\n    async def get_all_chats_for_user(self, db_manager: DatabaseManager):\\\\n        filters = {{"user_id": [self.user_id]}}\\\\n        if "AGENT_ID" in os.environ:\\\\n            filters["agent_id"] = os.getenv("AGENT_ID", "")\\\\n        if "SWARM_ID" in os.environ:\\\\n            filters["swarm_id"] = os.getenv("SWARM_ID", "")\\\\n        db_chat_history = await db_manager.read_data("chats", filters)\\\\n        chats_by_session: dict[str, list] = {}\\\\n        for chat in db_chat_history:\\\\n            session_id = chat["session_id"]\\\\n            if session_id not in chats_by_session:\\\\n                chats_by_session[session_id] = []\\\\n            chats_by_session[session_id].append(\\\\n                {{"message": chat["message"], "role": chat["role"], "timestamp": chat["timestamp"]}}\\\\n            )\\\\n        return chats_by_session\\\\n    async def generate_response(self, db_manager: Optional[DatabaseManager], last_message: ChatMessage, files: Optional[List[str]] = []) -> str:\\\\n        chat_history = []\\\\n        if db_manager is not None:\\\\n            chat_history = await self.get_messages(db_manager)\\\\n            await self.add_message(db_manager, last_message.role.value, last_message.content)\\\\n        if self.enable_multi_modal:\\\\n            image_documents = [ImageDocument(image=file_store.get_file(image_path)) for image_path in files if self.is_valid_image(image_path)] if files is not None and len(files) > 0 else []\\\\n            assistant_message = await self._handle_openai_multimodal(last_message, chat_history, image_documents)\\\\n        else:\\\\n            assistant_message = await self._handle_openai_agent(last_message, chat_history)\\\\n        if db_manager is not None:\\\\n            await self.add_message(db_manager, MessageRole.ASSISTANT, assistant_message)\\\\n        return assistant_message\\\\n    async def _handle_openai_multimodal(self, last_message: ChatMessage, chat_history: List[ChatMessage], image_documents: List[ImageDocument]) -> str:\\\\n        self.llm.memory = ChatMemoryBuffer.from_defaults(chat_history=chat_history)\\\\n        task = self.llm.create_task(str(last_message.content), extra_state={"image_docs": image_documents})\\\\n        return await self._execute_task(task.task_id)\\\\n    async def _handle_openai_agent(self, last_message: ChatMessage, chat_history: List[ChatMessage]) -> str:\\\\n        response_stream = await self.llm.astream_chat(last_message.content, chat_history=chat_history)\\\\n        return "".join([token async for token in response_stream.async_response_gen()]) \\\\\n    async def _execute_task(self, task_id: str) -> str:\\\\n        while True:\\\\n            try:\\\\n                response = await self.llm._arun_step(task_id)\\\\n                if response.is_last:\\\\n                    return str(self.llm.finalize_response(task_id))\\\\n            except Exception as e:\\\\n                return f"error during step execution: {str(e)}"\\"