import os\\nimport datetime, timezone, Path\\n\\nfrom llama_index.core.agent.runner.base import AgentRunner\\nfrom llama_index.core.llms import ChatMessage, MessageRole\\nfrom llama_index.core.memory import ChatMemoryBuffer\\nfrom llama_index.core.schema import ImageDocument\\n\\nfrom swarmzero.database.database import DatabaseManager\\nfrom swarmzero.filestore import BASE_DIR, FileStore\\n\\nfile_store = FileStore(BASE_DIR)\\\\n\\nclass ChatManager:\\\\\n    def __init__(self, llm: AgentRunner, user_id: str, session_id: str, enable_multi_modal: bool = False):\\n        self.llm = llm\\n        self.user_id = user_id\\n        self.session_id = session_id\\n        self.chat_store_key = f"{user_id}_{session_id}\\\"\\\\\n        self.enable_multi_modal = enable_multi_modal\\n\\n    async def add_message(self, db_manager: DatabaseManager, role: str, content: Any | None):\\n        data = {\\\"user_id\": self.user_id,\\\"session_id\": self.session_id,\\\"message\": content,\\\"role\": role,\\\"timestamp\": datetime.now(timezone.utc).isoformat()}\\\\\n        if "AGENT_ID" in os.environ:\\n            data["agent_id"] = os.getenv("AGENT_ID", "")\\\\\n        if "SWARM_ID" in os.environ:\\n            data["swarm_id"] = os.getenv("SWARM_ID", "")\\\\\n\\n        await db_manager.insert_data(\\\"chats\", data)\\\\\n\\n    async def get_messages(self, db_manager: DatabaseManager):\\n        filters = {"user_id": [self.user_id], "session_id": [self.session_id]}\\\\\n        if "AGENT_ID" in os.environ:\\n            filters["agent_id"] = os.getenv("AGENT_ID", "")\\\\\n        if "SWARM_ID" in os.environ:\\n            filters["swarm_id"] = os.getenv("SWARM_ID", "")\\\\\n\\n        db_chat_history = await db_manager.read_data("chats", filters)\\\\\n        chat_history = [ChatMessage(role=chat["role"], content=chat["message"]) for chat in db_chat_history]\\\n        return chat_history\\\\n\\n    async def get_all_chats_for_user(self, db_manager: DatabaseManager):\\n        filters = {"user_id": [self.user_id]}\\\\\n        if "AGENT_ID" in os.environ:\\n            filters["agent_id"] = os.getenv("AGENT_ID", "")\\\\\n        if "SWARM_ID" in os.environ:\\n            filters["swarm_id"] = os.getenv("SWARM_ID", "")\\\\\n\\n        db_chat_history = await db_manager.read_data("chats", filters)\\\\\n\\n        chats_by_session: dict[str, list] = {}\\\\\n        for chat in db_chat_history:\\n            session_id = chat["session_id"]\\n            if session_id not in chats_by_session:\\n                chats_by_session[session_id] = []\\n            chats_by_session[session_id].append(\\\\n                {\\\"message\": chat["message"],\\\"role\": chat["role"],\\\"timestamp\": chat["timestamp"]}\\\\\n            )\\\\\n\\n        return chats_by_session\\\\n\\n    async def generate_response(self, db_manager: Optional[DatabaseManager], last_message: ChatMessage, image_document_paths: Optional[List[str]] = []):\\n        chat_history = []\\n\\n        if db_manager is not None:\\n            chat_history = await self.get_messages(db_manager)\\\\\n            await self.add_message(db_manager, last_message.role.value, last_message.content)\\\\\n\\n        if self.enable_multi_modal:\\n            image_documents = (\\n                [ImageDocument(image=file_store.get_file(image_path)) for image_path in image_document_paths]\\n                if image_document_paths is not None and len(image_document_paths) > 0\\n                else []\\n            )\\\\\n            assistant_message = await self._handle_openai_multimodal(last_message, chat_history, image_documents)\\\\\n        else:\\n            assistant_message = await self._handle_openai_agent(last_message, chat_history)\\\\\n\\n        if db_manager is not None:\\n            await self.add_message(db_manager, MessageRole.ASSISTANT, assistant_message)\\\\\n\\n        return assistant_message\\\\n\\n    async def _handle_openai_multimodal(self, last_message: ChatMessage, chat_history: List[ChatMessage], image_documents: List[ImageDocument]):\\n        self.llm.memory = ChatMemoryBuffer.from_defaults(chat_history=chat_history)\\\\\n        task = self.llm.create_task(str(last_message.content), extra_state={"image_docs": image_documents})\\\\\n        return await self._execute_task(task.task_id)\\\\\n\\n    async def _handle_openai_agent(self, last_message: ChatMessage, chat_history: List[ChatMessage]):\\n        response_stream = await self.llm.astream_chat(last_message.content, chat_history=chat_history)\\\\\n        return "".join([token async for token in response_stream.async_response_gen()])\\\\\n\\n    async def _execute_task(self, task_id: str):\\n        while True:\\n            try:\\n                response = await self.llm._arun_step(task_id)\\\\\n                if response.is_last:\\n                    return str(self.llm.finalize_response(task_id))\\\\\n            except Exception as e:\\n                return f"error during step execution: {str(e)}""